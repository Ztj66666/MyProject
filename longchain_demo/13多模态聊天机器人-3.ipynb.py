import base64
import io
import uuid
import gradio as gr
from PIL import Image
from langchain_community.chat_message_histories import SQLChatMessageHistory
from langchain_core.messages import HumanMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnableWithMessageHistory

from longchain_demo.my_llm import llm

prompt = ChatPromptTemplate.from_messages(
    [
        ('system',"ä½ æ˜¯ä¸€ä¸ªå¤šæ¨¡æ€aiåŠ©æ‰‹ï¼Œå¯ä»¥å¤„ç†æ–‡æœ¬ï¼ŒéŸ³é¢‘å’Œå›¾åƒè¾“å…¥"),
        MessagesPlaceholder(variable_name="message")
    ]
)
chain = prompt | llm

def get_session_history(session_id:str):
    return SQLChatMessageHistory(
        session_id=session_id,
        connection_string= 'sqlite:///muti_chat.db',
    )

chain_with_message_history =RunnableWithMessageHistory(chain,
                                                       get_session_history,
                                                       input_messages_key='input',
                                                       history_messages_key='chat_history',
                                       )

chain_history = RunnableWithMessageHistory(
    chain,
    get_session_history,
)

config = {"configurable":{"session_id":str(uuid.uuid4())}}

def transcribe_audio(audio_path):
    """ä½¿ç”¨Base64å¤„ç†è¯­éŸ³è½¬ä¸º"""

    # ç›®å‰å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼š æ”¯æŒä¸¤ä¸ªä¼ å‚æ–¹å¼ï¼Œ1ã€base64ï¼ˆå­—ç¬¦ä¸²ï¼‰ï¼ˆæœ¬åœ°ï¼‰ã€‚2ã€ç½‘ç»œè®¿é—®çš„urlåœ°å€ï¼ˆå¤–ç½‘çš„æœåŠ¡å™¨ä¸Šï¼‰ http://sxxxx.com/11.mp3
    try:
        with open(audio_path, 'rb') as audio_file:
            audio_data = base64.b64encode(audio_file.read()).decode('utf-8')
        audio_message = {  # æŠŠéŸ³é¢‘æ–‡ä»¶ï¼Œå°è£…æˆä¸€æ¡æ¶ˆæ¯
            "type": "audio_url",
            "audio_url": {
                "url": f"data:audio/wav;base64,{audio_data}",
                "duration": 30  # å•ä½ï¼šç§’ï¼ˆå¸®åŠ©æ¨¡å‹ä¼˜åŒ–å¤„ç†ï¼‰
            }
        }

        return audio_message
    except Exception as e:
        print(e)
        return {}


def transcribe_image(image_path):
    """
    å°†ä»»æ„æ ¼å¼çš„å›¾ç‰‡è½¬æ¢ä¸ºbase64ç¼–ç çš„data URL
    :param image_path: å›¾ç‰‡è·¯å¾„
    :return: åŒ…å«base64ç¼–ç çš„å­—å…¸
    """
    with Image.open(image_path) as img:
        # è·å–åŸå§‹å›¾ç‰‡æ ¼å¼ï¼ˆå¦‚JPEG/PNGï¼‰
        img_format = img.format if img.format else 'JPEG'

        buffered = io.BytesIO()
        # ä¿ç•™åŸå§‹æ ¼å¼ï¼ˆé¿å…JPEGå¼ºåˆ¶è½¬æ¢å¯¼è‡´é€æ˜é€šé“ä¸¢å¤±ï¼‰
        img.save(buffered, format=img_format)

        image_data = base64.b64encode(buffered.getvalue()).decode('utf-8')
        return {
            "type": "image_url",
            "image_url": {
                "url": f"data:image/{img_format.lower()};base64,{image_data}",
                "detail": 'low'
            }
        }

def get_last_user_after_assistant(history):
    """åå‘éå†æ‰¾åˆ°æœ€åä¸€ä¸ªassistantçš„ä½ç½®,å¹¶è¿”å›åé¢çš„æ‰€æœ‰useræ¶ˆæ¯"""
    if not history:
        return None
    if history[-1]["role"] == "assistant":
        return None

    last_assistant_idx = -1
    for i in range(len(history) - 1, -1, -1):
        if history[i]["role"] == "assistant":
            last_assistant_idx = i
            break

    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°assistant
    if last_assistant_idx == -1:
        return history
    else:
        # ä»assistantä½ç½®å‘åæŸ¥æ‰¾ç¬¬ä¸€ä¸ªuser
        return history[last_assistant_idx + 1:]

def add_message(history,messages):
    for m in messages['files']:
        print(m)
        history.append({"role":"user","content":{'path':m}})
    if messages['text'] is not None:
        print(messages['text'])
        history.append({"role":"user","content":messages['text']})
    return history,''

def submit_messages(history):
    print(history[0]['content'])
    user_messages = get_last_user_after_assistant(history)
    print(user_messages)
    content=[]
    if user_messages:
        for m in user_messages:
            print(m['content'][0]['type'])
            if (m['content'][0]['type']=='text'):
                print("å­—ç¬¦ä¸²")
                content.append({'type':"text",'text':m['content']})
            elif (m['content'][0]['type']=='file'):
                file_path = m['content'][0]
                if file_path.endswith(".wav"):
                    print("éŸ³é¢‘")
                    file_message = transcribe_audio(file_path)
                elif file_path.endswith(".jpg") or file_path.endswith(".jpeg") or file_path.endswith(".png"):
                    file_message = transcribe_image(file_path)
                content.append(file_message)
            else:
                print(m)
                pass
    input_message = HumanMessage(content=content)
    resp = chain_history.invoke({'message':input_message},config=config)
    history.append({"role":"assistant","content":resp.content})

with gr.Blocks(title="å¤šæ¨¡æ€æœºå™¨äºº")as block:
    gr.Markdown("# ğŸ¤– å¤šæ¨¡æ€èŠå¤©æœºå™¨äºº")
    # ç§»é™¤ type='messages'
    chatbot = gr.Chatbot(height=500, label='èŠå¤©æœºå™¨äºº')
    chat_input = gr.MultimodalTextbox(
        interactive=True,
        file_types=['image','.wav','.mp4'],
        file_count="multiple",
        placeholder="è¯·è¾“å…¥ä¿¡æ¯æˆ–è€…ä¸Šä¼ æ–‡ä»¶",
        show_label=False,
        sources=["microphone","upload"]
    )
    chat_input.submit(
        add_message,
        [chatbot,chat_input],
        [chatbot,chat_input]
    ).then(
        submit_messages,
        [chatbot],
        [chatbot]
    ).then(
        lambda : gr.MultimodalTextbox(interactive=True,),
        None,
        [chat_input]
    )
if __name__ == '__main__':
    block.launch()

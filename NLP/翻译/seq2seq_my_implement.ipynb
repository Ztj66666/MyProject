{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3bbaf1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import dltools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3116feca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "    def forward(self,X,*args):\n",
    "        return NotImplementedError\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "    def __init_state__(self,eng_output,*args):\n",
    "        return NotImplementedError\n",
    "    def forward(self,X,*args):\n",
    "        return NotImplementedError\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ab64564f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqEncoder(Encoder):\n",
    "    def __init__(self,vocab_size,embed_size,num_hiddens,num_layers,dropout=0.0, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.embedding = nn.Embedding(vocab_size,embed_size)\n",
    "        self.rnn = nn.GRU(embed_size,num_hiddens,num_layers,dropout=dropout if num_layers > 1 else 0.0)\n",
    "    def forward(self,X,*args):\n",
    "        X = self.embedding(X)\n",
    "        X = X.permute(1,0,2)\n",
    "        enc_output,enc_state = self.rnn(X)\n",
    "        return enc_output,enc_state\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "94148236",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqDecoder(Decoder):\n",
    "    def __init__(self,vocab_size,embed_size,num_hiddens,num_layer,dropout=0.0, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.embedding = nn.Embedding(vocab_size,embed_size)\n",
    "        self.rnn = nn.GRU(embed_size + num_hiddens,num_hiddens,num_layer,dropout=dropout if num_layer >1 else 0.0)\n",
    "        self.dense = nn.Linear(num_hiddens,vocab_size)\n",
    "    def init_state(self, eng_output, *args):\n",
    "        return eng_output[1]\n",
    "    def forward(self, X,state):\n",
    "        X = self.embedding(X).permute(1,0,2)\n",
    "      \n",
    "        context = state[-1].repeat(X.shape[0],1,1)\n",
    "        X_and_context = torch.cat([X,context],dim=2)\n",
    "        output,new_state = self.rnn(X_and_context)\n",
    "        logits = self.dense(output).permute(1,0,2)\n",
    "        return logits,new_state\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "03a20421",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self,encoder,decoder, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self,enc_X,dec_X,*args):\n",
    "        X = self.encoder(enc_X)\n",
    "        state = self.decoder.init_state(X)\n",
    "        print( state[-1].shape)\n",
    "        return self.decoder(dec_X,state)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "78ba2c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 16])\n",
      "encoder → (time_outputs, final_state) shapes:\n",
      "  time_outputs: torch.Size([7, 4, 16])\n",
      "  final_state: torch.Size([2, 4, 16])\n",
      "\n",
      "decoder/net outputs:\n",
      "  logits: torch.Size([4, 6, 150])\n",
      "  dec_state: torch.Size([2, 4, 16])\n"
     ]
    }
   ],
   "source": [
    "# ==== 超参数 ====\n",
    "src_vocab = 200\n",
    "tgt_vocab = 150\n",
    "embed_size = 8\n",
    "hidden_size = 16\n",
    "num_layer = 2\n",
    "\n",
    "# ==== 模块实例 ====\n",
    "encoder = Seq2SeqEncoder(\n",
    "    vocab_size=src_vocab,\n",
    "    embed_size=embed_size,\n",
    "    num_hiddens=hidden_size,\n",
    "    num_layers=num_layer\n",
    ")\n",
    "decoder = Seq2SeqDecoder(\n",
    "    vocab_size=tgt_vocab,\n",
    "    embed_size=embed_size,\n",
    "    num_hiddens=hidden_size,\n",
    "    num_layer=num_layer  # 注意这里叫 num_layer（单数），值与 encoder 对齐\n",
    ")\n",
    "net = EncoderDecoder(encoder, decoder)\n",
    "\n",
    "# ==== 伪造一批数据 ====\n",
    "batch_size = 4\n",
    "src_len = 7\n",
    "tgt_len = 6\n",
    "enc_X = torch.zeros((batch_size, src_len), dtype=torch.long)  # 假装是源句\n",
    "# 训练时 dec_X 通常是 <bos> + gold[:-1]；这里只做连通性测试\n",
    "dec_X = torch.zeros((batch_size, tgt_len), dtype=torch.long)\n",
    "\n",
    "# ==== 前向 ====\n",
    "logits, dec_state = net(enc_X, dec_X)\n",
    "\n",
    "print(\"encoder → (time_outputs, final_state) shapes:\")\n",
    "enc_time_out, enc_final_state = encoder(enc_X)\n",
    "print(\"  time_outputs:\", enc_time_out.shape)      # [S, B, H] = [7, 4, 16]\n",
    "print(\"  final_state:\", enc_final_state.shape)    # [L, B, H] = [2, 4, 16]\n",
    "\n",
    "print(\"\\ndecoder/net outputs:\")\n",
    "print(\"  logits:\", logits.shape)                  # [B, T, V] = [4, 6, 150]\n",
    "print(\"  dec_state:\", dec_state.shape)            # [L, B, H] = [2, 4, 16]\n",
    "\n",
    "# 可选断言（自检失败会抛错）\n",
    "assert enc_time_out.shape == (src_len, batch_size, hidden_size)\n",
    "assert enc_final_state.shape == (num_layer, batch_size, hidden_size)\n",
    "assert logits.shape == (batch_size, tgt_len, tgt_vocab)\n",
    "assert dec_state.shape == (num_layer, batch_size, hidden_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf2b03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 0, 0],\n",
      "        [6, 7, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "def sequence_mask(X,valid_len,value = 0):\n",
    "    max_len = X.size(1)\n",
    "    mask = torch.arange(max_len,device=X.device)[None] < valid_len[:,None]\n",
    "    X[~mask] =value\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "29d55a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedSeqMaxSEloss(nn.CrossEntropyLoss):\n",
    "    def forward(self,pred,label,valid_len):\n",
    "        weight = torch.ones_like(label)\n",
    "        weight = sequence_mask(weight,valid_len)\n",
    "        self.reduction ='none'\n",
    "        unweighted_loss = super().forward(pred.permute(0,2,1),label)\n",
    "        weighted_loss = (unweighted_loss * weight).mean(dim=1)\n",
    "        return weighted_loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3c9274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_seq2seq(net,train_iter,lr,num_epochs,device,tgt_vocab):\n",
    "    def xavier_init_weight(m):\n",
    "        if type(m) == nn.Linear:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "        if type(m) == nn.GRU:\n",
    "            for param in m._flat_weights_names:\n",
    "                if 'weight' in param:\n",
    "                    nn.init.xavier_uniform_(m._parameters[param])\n",
    "    net.apply(xavier_init_weight)\n",
    "    net = net = net.to(device)\n",
    "    optimizer = torch.optim.Adam(net.parameters(),lr=lr)\n",
    "    loss = MaskedSeqMaxSEloss()\n",
    "    animater = dltools.Animator(xlabel='epoch',ylabel='loss',xlim=[10,num_epochs])\n",
    "    for batch in train_iter:\n",
    "        timer = dltools.Timer()\n",
    "        metric = dltools.Accumulator(2)\n",
    "        optimizer.zero_grad()\n",
    "        X,X_valid_len,Y,Y_valid_len = [x.to(device) for x in batch]\n",
    "        bos = torch.tensor([tgt_vocab['<bos>']]*Y.shape[0],device=device).reshape(-1,1)\n",
    "        dec_input = torch.cat([bos,Y[:,:-1]],1)\n",
    "        Y_pre,_=net(X,dec_input,X_valid_len)\n",
    "        l = loss(Y_pre,Y,Y_valid_len)\n",
    "        l.sum().backward()\n",
    "        optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            metric.add(l.sum(),num_token)\n",
    "    if (epoch +1 )% 10 ==0:\n",
    "        animator.add(epoch+1,(metric[0]/metric[1]))\n",
    "    print(f'loss {metric[0]/metric[1]:.3f},{metric[1]/timer.stop():.1f}',f'tokens/sec on {str(device)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2fbfcb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 32])\n",
      "tensor([2.1040, 2.6693, 2.1642, 2.1670, 3.2551, 2.6721, 2.1586, 1.6176, 3.2182,\n",
      "        2.1417, 2.1398, 1.6139, 2.7057, 2.1426, 2.6892, 2.6750, 1.5876, 2.7035,\n",
      "        1.6113, 2.1604, 2.6914, 1.6142, 2.1656, 2.1364, 1.6152, 2.7010, 1.6057,\n",
      "        2.7059, 2.6964, 2.6809, 2.1419, 1.5995, 1.6197, 1.6010, 2.1467, 2.1670,\n",
      "        1.6158, 2.1178, 2.1450, 1.6075, 2.7082, 1.5907, 2.1250, 2.1173, 1.6053,\n",
      "        2.1488, 2.6436, 2.6693, 3.2181, 2.6771, 3.2543, 2.6770, 2.1488, 2.1358,\n",
      "        2.1453, 2.6741, 1.5991, 1.5995, 2.1191, 3.1952, 2.1414, 3.7958, 2.6956,\n",
      "        3.2589], device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "torch.Size([64, 32])\n",
      "tensor([1.5436, 2.6159, 1.5567, 1.5755, 1.5431, 2.0937, 2.6548, 2.0854, 2.6092,\n",
      "        2.6196, 3.2108, 2.0641, 2.6331, 2.6521, 1.5804, 2.6183, 3.0936, 2.5996,\n",
      "        1.5469, 2.6280, 2.6460, 2.1269, 2.0716, 1.5671, 3.6931, 2.0728, 1.5732,\n",
      "        1.5508, 2.6365, 1.5600, 2.6254, 1.5505, 2.5971, 1.6007, 2.0861, 2.6233,\n",
      "        2.0794, 1.5434, 2.0839, 2.0795, 1.5459, 2.6636, 1.5711, 2.6503, 1.5519,\n",
      "        1.5703, 2.6302, 3.1469, 2.6259, 2.6299, 2.1163, 2.1061, 2.6230, 1.5953,\n",
      "        2.1071, 3.6888, 1.5726, 1.5493, 2.1150, 3.6656, 2.0799, 2.6188, 2.6369,\n",
      "        2.1517], device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "torch.Size([64, 32])\n",
      "tensor([1.4948, 2.0550, 1.5182, 1.5133, 2.0751, 2.0115, 2.5483, 1.4941, 1.5302,\n",
      "        3.0072, 1.5354, 1.5042, 2.0124, 2.0492, 1.5285, 2.5721, 1.5092, 3.1126,\n",
      "        2.5755, 2.5429, 1.5173, 1.5182, 1.5047, 2.5273, 2.5513, 1.4941, 2.0267,\n",
      "        2.5164, 2.0233, 2.0425, 1.5170, 2.5916, 2.5501, 4.0686, 1.5275, 2.0704,\n",
      "        2.0142, 1.4982, 1.9942, 2.0839, 3.1126, 2.0593, 2.0387, 2.0270, 3.0804,\n",
      "        2.5441, 1.9878, 1.5199, 2.0421, 2.0280, 2.0792, 2.5752, 2.5744, 1.5334,\n",
      "        2.6096, 2.0142, 1.9779, 2.0256, 1.9828, 1.4871, 3.0142, 2.0413, 1.5459,\n",
      "        1.4941], device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "torch.Size([64, 32])\n",
      "tensor([1.4977, 1.4703, 1.9872, 1.4200, 1.4643, 3.0265, 2.5025, 1.4303, 2.5537,\n",
      "        1.9628, 1.9602, 2.5483, 1.5018, 1.9707, 1.4660, 1.4596, 1.4351, 1.9465,\n",
      "        1.4284, 3.6062, 1.4782, 2.9974, 1.9539, 1.9778, 1.9684, 3.1677, 2.4584,\n",
      "        2.4841, 1.4266, 2.0064, 3.0854, 1.9669, 1.4562, 1.9370, 2.4633, 1.9596,\n",
      "        2.0242, 2.5002, 1.4728, 2.5316, 2.5008, 1.9860, 2.9844, 3.0033, 1.9678,\n",
      "        3.1860, 2.0146, 1.9419, 2.0579, 2.4511, 1.9406, 1.4637, 2.5357, 1.9866,\n",
      "        1.4346, 1.4259, 1.4980, 2.4457, 2.4871, 2.5645, 2.5085, 1.9968, 1.4655,\n",
      "        1.9488], device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "torch.Size([64, 32])\n",
      "tensor([1.4135, 1.4037, 2.5389, 1.3972, 2.3950, 2.4089, 1.3586, 2.3648, 1.8543,\n",
      "        2.5172, 1.4104, 2.3776, 2.3319, 1.4009, 1.3760, 1.4617, 2.4682, 1.9719,\n",
      "        1.4376, 2.3919, 1.4359, 1.4409, 2.6057, 1.8642, 1.3537, 2.2943, 1.8720,\n",
      "        1.4010, 3.5678, 1.4167, 2.4476, 2.4791, 1.4087, 1.3834, 2.8791, 1.4954,\n",
      "        2.4921, 2.3828, 2.3922, 1.4111, 2.4224, 1.9623, 2.4632, 2.5074, 1.3588,\n",
      "        2.3570, 1.3470, 1.9268, 1.9267, 1.9680, 1.9348, 2.4351, 2.3533, 3.3979,\n",
      "        1.4293, 2.3499, 1.3841, 1.9719, 1.8885, 1.8621, 2.4039, 2.5033, 1.8626,\n",
      "        1.9430], device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "torch.Size([64, 32])\n",
      "tensor([1.8337, 1.9427, 2.2553, 1.8770, 2.4114, 2.3889, 2.3164, 1.7992, 2.1753,\n",
      "        1.8226, 1.3317, 1.3389, 1.3508, 1.7760, 2.3546, 1.4054, 1.3695, 1.9076,\n",
      "        2.4343, 1.8580, 1.7903, 2.8064, 1.3474, 1.8658, 1.8047, 2.3938, 1.8259,\n",
      "        2.3721, 1.8297, 1.9120, 2.4067, 1.3428, 2.3111, 1.7194, 1.8002, 2.3579,\n",
      "        1.8480, 1.7518, 2.8994, 2.3493, 1.9203, 2.2468, 2.3313, 2.3968, 1.2909,\n",
      "        1.8324, 2.2750, 2.2419, 2.4587, 1.3329, 1.7636, 1.8215, 2.4027, 1.3442,\n",
      "        3.8699, 3.9301, 1.7824, 2.3228, 1.2673, 2.2921, 1.8713, 2.0120, 1.8602,\n",
      "        2.2857], device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "torch.Size([64, 32])\n",
      "tensor([2.3225, 2.1380, 1.7807, 1.6757, 2.4365, 1.6604, 1.2858, 2.1791, 2.1906,\n",
      "        1.3094, 1.2714, 1.2030, 1.2753, 1.6857, 1.8436, 2.3262, 1.9095, 1.1977,\n",
      "        2.0624, 2.2753, 1.3419, 1.7799, 1.6508, 2.3007, 1.8036, 1.2008, 1.2569,\n",
      "        1.2055, 2.5416, 1.2049, 2.2433, 2.1344, 2.2104, 1.3264, 1.8229, 2.2468,\n",
      "        1.7563, 1.8388, 2.2250, 2.9527, 2.0441, 2.2244, 1.7337, 1.3845, 2.3108,\n",
      "        2.2621, 2.1407, 1.6624, 2.1798, 1.6588, 1.2038, 2.3328, 2.1294, 1.2586,\n",
      "        1.2194, 2.2210, 2.4456, 2.1906, 2.2428, 2.2725, 2.2877, 1.7705, 1.2684,\n",
      "        1.7955], device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "torch.Size([64, 32])\n",
      "tensor([1.1971, 2.0435, 2.0989, 2.3582, 2.1622, 1.7067, 1.6655, 1.7906, 2.8491,\n",
      "        1.7157, 1.1288, 1.7111, 1.6704, 2.2747, 1.7059, 1.7344, 1.6821, 2.7654,\n",
      "        1.6541, 1.6288, 2.1129, 1.5978, 1.2252, 1.2693, 1.5284, 2.1373, 1.6762,\n",
      "        2.1827, 1.1918, 2.1608, 2.1921, 1.1221, 1.1995, 2.2691, 1.6550, 2.1434,\n",
      "        1.1179, 1.1118, 2.0185, 2.0944, 1.1216, 1.2717, 1.6326, 2.1445, 1.1182,\n",
      "        1.1259, 2.0408, 1.7683, 2.0424, 2.5945, 1.2162, 1.4949, 2.3172, 1.7244,\n",
      "        1.7142, 1.1363, 1.7849, 1.5324, 2.2248, 2.1440, 1.2354, 3.0913, 2.2257,\n",
      "        1.1295], device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "torch.Size([64, 32])\n",
      "tensor([2.7344, 2.1872, 1.4226, 1.1276, 1.1246, 1.5933, 1.0321, 1.0280, 1.6224,\n",
      "        3.2122, 1.0356, 1.1822, 2.2057, 2.1217, 2.9922, 1.1401, 2.7986, 1.5867,\n",
      "        2.0373, 1.4538, 1.1445, 1.1480, 1.5697, 1.1565, 1.9138, 1.0505, 2.1477,\n",
      "        1.1522, 2.0963, 3.1949, 2.2529, 2.2484, 1.2164, 1.9068, 1.4469, 2.2029,\n",
      "        1.2929, 2.0181, 1.6742, 2.7862, 2.1905, 2.6408, 2.1678, 1.6232, 1.1892,\n",
      "        2.2074, 1.6751, 1.1206, 1.0250, 1.0311, 2.2578, 1.6708, 1.7500, 1.0525,\n",
      "        2.0699, 1.5781, 1.6723, 1.5595, 1.0494, 2.1299, 1.1298, 2.2856, 1.5909,\n",
      "        1.5739], device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "torch.Size([25, 32])\n",
      "tensor([0.9546, 2.6614, 1.8958, 1.3971, 1.6233, 1.9472, 1.6218, 1.6919, 2.2216,\n",
      "        1.0912, 1.8231, 1.0649, 2.1092, 1.1134, 2.0484, 1.5002, 2.7543, 2.0604,\n",
      "        1.1101, 1.6168, 1.4890, 1.6445, 1.8034, 1.1448, 2.1305],\n",
      "       device='cuda:0', grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "embed_size,num_hiddens,num_layers,dropout = 32,32,2,0.1\n",
    "batch_size,num_steps = 64,10\n",
    "lr,num_epoches,device = 0.005,100,dltools.try_gpu()\n",
    "train_iter,src_vocab,tgt_vocab = dltools.load_data_nmt(batch_size,num_steps)\n",
    "encoder = Seq2SeqEncoder(len(src_vocab),embed_size,num_hiddens,num_layers,dropout)\n",
    "decoder = Seq2SeqDecoder(len(tgt_vocab),embed_size,num_hiddens,num_layers,dropout)\n",
    "net = EncoderDecoder(encoder,decoder)\n",
    "train_seq2seq(net,train_iter,lr,num_epoches,device,tgt_vocab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hello_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
